---
title: "Solutions for hw 5"
output: github_document
date: "2024-11-16"
---

```{r setup, include=FALSE}
library(broom)
library(dplyr)
library(ggplot2)
library(purrr)

# Initialize parameters
n <- 30
sigma <- 5
mu_0 <- 0
iterations <- 5000
alpha <- 0.05
```

```{R}
# Function to simulate data and compute statistics
generate_data <- function(mean_value, sample_size, sd, num_iterations) {
  data <- tibble(
    iteration = 1:num_iterations,
    sample = replicate(num_iterations, rnorm(sample_size, mean = mean_value, sd = sd), simplify = FALSE)
  ) |>
  mutate(
    sample_mean = map_dbl(sample, mean),
    test_result = map(sample, ~ broom::tidy(t.test(.x, mu = 0))),
    p_value = map_dbl(test_result, "p.value")
  )
  
  return(data)
}

# Specify mean values for the simulations
mu_values <- c(0, 1, 2, 3, 4, 5, 6)

# Run simulations for each mean value
simulations <- lapply(mu_values, function(mu) {
  generate_data(mu, n, sigma, iterations)
})

# Combine results into a single data frame
simulation_results <- bind_rows(lapply(1:length(mu_values), function(i) {
  simulations[[i]] |>
    mutate(true_mean = mu_values[i])
}))
```

```{R}
# Calculate power (rejection rate) for each true mean value
power_data <- simulation_results |>
  group_by(true_mean) |>
  summarize(power = mean(p_value < alpha))

# Plot power vs. true mean
ggplot(power_data, aes(x = true_mean, y = power)) +
  geom_line() +
  geom_point() +
  labs(title = "Power of the Test vs. True Mean", x = "True Mean (μ)", y = "Power (Rejection Rate)") +
  theme_minimal()
```

As the true value of mu increases (the effect size becomes larger), the power of the test also increases. Reason: Larger effect sizes are easier to detect, making it more likely that the test will correctly reject the null hypothesis.

```{R}
# Calculate average estimates
avg_estimates <- simulation_results |>
  group_by(true_mean) |>
  summarize(
    avg_estimate_all = mean(sample_mean),
    avg_estimate_rejected = mean(sample_mean[p_value < alpha])
  )

# Plot average estimates
ggplot(avg_estimates, aes(x = true_mean)) +
  geom_line(aes(y = avg_estimate_all, color = "All Samples"), linetype = "dotted") +
  geom_point(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_line(aes(y = avg_estimate_rejected, color = "Rejected Samples"), linetype = "solid") +
  geom_point(aes(y = avg_estimate_rejected, color = "Rejected Samples")) +
  labs(title = "Average Estimates of μ̂ vs. True Mean", x = "True Mean (μ)", y = "Average Estimate of μ̂", color = "Sample Group") +
  scale_color_manual(values = c("All Samples" = "blue", "Rejected Samples" = "red")) +
  theme_minimal()
```

For high value of mu: Both averages converge.
For low value of mu: Rejected samples show higher means due to selection bias—tests that reject typically have larger sample means.

```{R}
hom_data = read.csv("homicide-data.csv")|>
  janitor::clean_names()
view(hom_data)
```

Description of the data: Contains 52179 observations and has 12 variables. These observations are the records of the homicide variables and each variable gives us the information of the corresponding case. Example, city variable gives us the city where the incident was recorded, victim_sex gives us the sex of the victim of the homicide etc.

```{R}
hom_data2 = hom_data |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")))

hom_data2 |> 
  head(8) |> #showing some observations to show that our code words
  knitr::kable()
```

```{R}
balt_data = hom_data2 |>
  filter(city_state == "Baltimore, MD")
balt_test = prop.test(balt_data$unsolved_homicides, balt_data$total_homicides) |>
  broom::tidy()
conf_int_balt = c(balt_test$conf.low[1], balt_test$conf.high[1])
print("The confidence interval is:")
paste(conf_int_balt)
```

```{R}
# Apply prop.test for each city and tidy the results
results2 = hom_data2 |>
  mutate(
    test_results = map2(unsolved_homicides, total_homicides, ~ broom::tidy(prop.test(.x, .y)))
  ) |>
  unnest(test_results) |>
  select(city_state, estimate, conf.low, conf.high) |>
  janitor::clean_names() |>
  arrange(desc(estimate))
print(head(results2, n = 5))
```
```{R}
# Create the plot with error bars
ggplot(results2, aes(x = city_state, y = estimate)) +
  geom_point(size = 3, color = "blue") +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width = 0.2, color = "red") +
  labs(title = "Proportion of Unsolved Homicides by City",
       x = "City",
       y = "Estimated Proportion of Unsolved Homicides") +
  theme_minimal() +
  coord_flip()  # Flip coordinates for better readability


```
